{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09ace569-1ce2-42d2-9b12-a70372262abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Laptop Recommendation Chatbot ===\n",
      "\n",
      "üßë User: I want a lightweight laptop with long battery life for business trips.\n",
      "ü§ñ RAG Answer: The first option in your list fits your needs best: a lightweight business laptop with an Intel i7, 16 GB RAM and long battery life ‚Äî designed for productivity and travel. \n",
      "\n",
      "If you want, I can:\n",
      "- Find specific models that match those specs,\n",
      "- Compare screen sizes, weight, and port selection,\n",
      "- Help pick one within a budget or recommend travel accessories (charger, sleeve, dongles).\n",
      "\n",
      "What‚Äôs your budget and do you have preferred screen size or operating system?\n",
      "‚öôÔ∏è Function Call Answer: \n",
      "\n",
      "üßë User: I need a laptop for gaming with the best graphics card available.\n",
      "ü§ñ RAG Answer: From the options you gave, the high-end gaming laptop with the NVIDIA RTX 4080, 32 GB RAM, and 1 TB SSD is the best choice ‚Äî it‚Äôs built for hardcore gaming and has the top-tier GPU in that set. Would you like help comparing models, checking display/thermal specs, or finding one in your budget?\n",
      "‚öôÔ∏è Function Call Answer: \n",
      "\n",
      "üßë User: Looking for a budget laptop suitable for student tasks and general browsing.\n",
      "ü§ñ RAG Answer: Yes ‚Äî from what you described, the best fit is an affordable laptop with 8 GB RAM, a 256 GB SSD, and a reliable battery. That configuration covers the typical student tasks (web browsing, video calls, documents, light multitasking) and gives fast boot/load times thanks to the SSD.\n",
      "\n",
      "Quick buying tips:\n",
      "- CPU: a recent Intel Core i3/i5 or AMD Ryzen 3/5 (or equivalent) is plenty for student work.\n",
      "- Screen: 13‚Äì15\" 1080p for a good balance of portability and readability.\n",
      "- Battery: aim for a model rated ~8+ hours in real-world use.\n",
      "- Ports & webcam: at least one USB-A, one USB-C (ideally with power/data), HDMI or a dongle-capable option, and a decent webcam for classes.\n",
      "- Upgradability: if possible, choose a laptop where you can add RAM or swap the SSD later.\n",
      "- OS: Windows or ChromeOS both work; Chromebooks can be cheaper if you mainly use web apps.\n",
      "\n",
      "If you want, tell me your target price, preferred screen size, or OS and I can suggest specific models.\n",
      "‚öôÔ∏è Function Call Answer: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_openai import AzureOpenAIEmbeddings, AzureChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import openai as openai_sdk  # d√πng ri√™ng cho function calling\n",
    "\n",
    "# ===============================\n",
    "# 0Ô∏è‚É£ Load environment variables\n",
    "# ===============================\n",
    "load_dotenv()\n",
    "\n",
    "# ===============================\n",
    "# 1Ô∏è‚É£ Function ki·ªÉm tra tr·∫°ng th√°i h·ªá th·ªëng (demo function call)\n",
    "# ===============================\n",
    "def check_system_status(device_id: str) -> str:\n",
    "    status_map = {\n",
    "        \"printer01\": \"Online and functioning normally.\",\n",
    "        \"router23\": \"Offline - requires restart.\",\n",
    "        \"server07\": \"Online but high CPU usage.\",\n",
    "    }\n",
    "    return status_map.get(device_id, \"Device not found.\")\n",
    "\n",
    "# ===============================\n",
    "# 2Ô∏è‚É£ D·ªØ li·ªáu laptop\n",
    "# ===============================\n",
    "laptops = [\n",
    "    {\n",
    "        \"id\": \"1\",\n",
    "        \"name\": \"Gaming Beast Pro\",\n",
    "        \"description\": \"A high-end gaming laptop with RTX 4080, 32GB RAM, and 1TB SSD. Perfect for hardcore gaming.\",\n",
    "        \"tags\": \"gaming, high-performance, windows\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"2\",\n",
    "        \"name\": \"Business Ultrabook X1\",\n",
    "        \"description\": \"A lightweight business laptop with Intel i7, 16GB RAM, and long battery life. Great for productivity.\",\n",
    "        \"tags\": \"business, ultrabook, lightweight\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"3\",\n",
    "        \"name\": \"Student Basic\",\n",
    "        \"description\": \"Affordable laptop with 8GB RAM, 256GB SSD, and a reliable battery. Ideal for students and general use.\",\n",
    "        \"tags\": \"student, budget, general\"\n",
    "    },\n",
    "]\n",
    "\n",
    "# ===============================\n",
    "# 3Ô∏è‚É£ Azure OpenAI Embeddings (chu·∫©n)\n",
    "# ===============================\n",
    "embedding_model = AzureOpenAIEmbeddings(\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_EMBEDDING_API_KEY\"),\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_EMBEDDING_ENDPOINT\"),\n",
    "    model=os.getenv(\"AZURE_OPENAI_EMBEDDING_MODEL\"),  # v√≠ d·ª•: text-embedding-3-small\n",
    "    api_version=\"2023-05-15\"\n",
    ")\n",
    "\n",
    "# ===============================\n",
    "# 4Ô∏è‚É£ Pinecone setup\n",
    "# ===============================\n",
    "pc = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
    "index_name = \"bot-laptop-index\"\n",
    "\n",
    "# Ch·ªâ t·∫°o index n·∫øu ch∆∞a c√≥\n",
    "if index_name not in [i[\"name\"] for i in pc.list_indexes()]:\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=1536,\n",
    "        metric=\"dotproduct\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
    "    )\n",
    "\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "# ===============================\n",
    "# 5Ô∏è‚É£ Azure Chat Model (chu·∫©n LangChain)\n",
    "# ===============================\n",
    "chat = AzureChatOpenAI(\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_LLM_API_KEY\"),\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_LLM_ENDPOINT\"),\n",
    "    api_version=\"2023-05-15\",\n",
    "    deployment_name=os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\"),  # v√≠ d·ª•: gpt-4o-mini\n",
    "    temperature=1,\n",
    ")\n",
    "\n",
    "# ===============================\n",
    "# 6Ô∏è‚É£ T·∫°o embeddings v√† upsert v√†o Pinecone\n",
    "# ===============================\n",
    "def get_embedding(text: str):\n",
    "    \"\"\"Sinh embedding t·ª´ text.\"\"\"\n",
    "    return embedding_model.embed_query(text)\n",
    "\n",
    "vectors = []\n",
    "for p in laptops:\n",
    "    embedding = get_embedding(p[\"name\"] + \" \" + p[\"description\"])\n",
    "    vectors.append((p[\"id\"], embedding, {\"text\": p[\"description\"]}))\n",
    "\n",
    "# upsert v√†o Pinecone\n",
    "index.upsert(vectors)\n",
    "\n",
    "# ===============================\n",
    "# 7Ô∏è‚É£ LangChain retriever\n",
    "# ===============================\n",
    "vectorstore = PineconeVectorStore(index=index, embedding=embedding_model, text_key=\"text\")\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "retrieval_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=chat,\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    ")\n",
    "\n",
    "# ===============================\n",
    "# 8Ô∏è‚É£ Function metadata cho function calling\n",
    "# ===============================\n",
    "functions = [\n",
    "    {\n",
    "        \"name\": \"recommend_laptop\",\n",
    "        \"description\": \"Recommends the most suitable laptop based on user needs, budget, and preferences.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"usage_purpose\": {\"type\": \"string\"},\n",
    "                \"budget_range\": {\"type\": \"string\"},\n",
    "                \"preferred_tags\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
    "            },\n",
    "            \"required\": [\"usage_purpose\"],\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"get_laptop_details\",\n",
    "        \"description\": \"Get laptop details by ID.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\"laptop_id\": {\"type\": \"string\"}},\n",
    "            \"required\": [\"laptop_id\"],\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"check_system_status\",\n",
    "        \"description\": \"Check IT device status.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\"device_id\": {\"type\": \"string\"}},\n",
    "            \"required\": [\"device_id\"],\n",
    "        },\n",
    "    },\n",
    "]\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are a helpful assistant specializing in laptop recommendations. \"\n",
    "    \"Use the context to suggest the best laptop for each query.\"\n",
    ")\n",
    "\n",
    "# ===============================\n",
    "# 9Ô∏è‚É£ Function chat_with_functions\n",
    "# ===============================\n",
    "from openai import OpenAI\n",
    "\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "def chat_with_functions(user_input, chat_history):\n",
    "    \"\"\"Function calling qua Azure OpenAI SDK v1.\"\"\"\n",
    "    client = AzureOpenAI(\n",
    "        api_key=os.getenv(\"AZURE_OPENAI_LLM_API_KEY\"),\n",
    "        azure_endpoint=os.getenv(\"AZURE_OPENAI_LLM_ENDPOINT\"),\n",
    "        api_version=\"2023-05-15\",\n",
    "    )\n",
    "\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "    for q, a in chat_history:\n",
    "        messages.append({\"role\": \"user\", \"content\": q})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": a})\n",
    "    messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\"),  # v√≠ d·ª• gpt-4o-mini\n",
    "        messages=messages,\n",
    "        functions=functions,\n",
    "        function_call=\"auto\"\n",
    "    )\n",
    "\n",
    "    message = response.choices[0].message\n",
    "    if message.function_call:\n",
    "        func_name = message.function_call.name\n",
    "        args = json.loads(message.function_call.arguments)\n",
    "        if func_name == \"check_system_status\":\n",
    "            result = check_system_status(args[\"device_id\"])\n",
    "            chat_history.append((user_input, result))\n",
    "            return result, chat_history\n",
    "\n",
    "    reply = message.content or \"\"\n",
    "    chat_history.append((user_input, reply))\n",
    "    return reply, chat_history\n",
    "\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# üîü Ch·∫°y batch queries\n",
    "# ===============================\n",
    "user_queries = [\n",
    "    \"I want a lightweight laptop with long battery life for business trips.\",\n",
    "    \"I need a laptop for gaming with the best graphics card available.\",\n",
    "    \"Looking for a budget laptop suitable for student tasks and general browsing.\",\n",
    "]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    chat_history = []\n",
    "    print(\"=== Laptop Recommendation Chatbot ===\\n\")\n",
    "\n",
    "    for query in user_queries:\n",
    "        print(f\"üßë User: {query}\")\n",
    "        rag_result = retrieval_chain({\"question\": query, \"chat_history\": chat_history})\n",
    "        print(f\"ü§ñ RAG Answer: {rag_result['answer']}\")\n",
    "        func_answer, chat_history = chat_with_functions(query, chat_history)\n",
    "        print(f\"‚öôÔ∏è Function Call Answer: {func_answer}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73773a5-faba-49f9-ba7a-4708a40a6c4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a951c0-a9fa-45f4-9e85-c64f9e6c52ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
